{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive nuclear segmentation notebook\n",
    "For internal Finn Lab use; Rehaul as of May, 2023\n",
    "\n",
    "#### Will: \n",
    "1) Find images (formatted for ImageXpress files)\n",
    "2) Load 9 at random\n",
    "3) Filter using an unsharp filter and Richardson-Lucy deconvolution\n",
    "4) Run filtered images through segmentation using CellPose\n",
    "5) Display CellPose results\n",
    "\n",
    "Add notes here as you like!\n",
    "\n",
    "#### First, set basic parameters such as microscope used and channel assignments. Microscope needs to be set as an environment variable, so do this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "IMAGE_LOCATION = \"/hpc-prj/finn/data/AG/\"\n",
    "ANALYSIS_PREFIX = \"20230713\"\n",
    "MICROSCOPE = \"LSM\"\n",
    "USER = \"butlerm\"\n",
    "DAPI_CHANNEL = 1\n",
    "NUCLEAR_DIAMETER = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies and set environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"FILE_TYPE\"] = MICROSCOPE\n",
    "os.environ[\"USER\"] = USER\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "import re\n",
    "import skimage\n",
    "\n",
    "from generate_maximum_projection import *\n",
    "from models.image_filename import *\n",
    "from models.image_filename_glob import *\n",
    "from models.paths import *\n",
    "from models.labels import *\n",
    "from models.swarm_job import SwarmJob, RunStrategy\n",
    "\n",
    "from generate_all_maximum_projections import GenerateAllMaximumProjectionsJob\n",
    "from generate_all_nuclear_segmentations import GenerateAllNuclearSegmentationsJob\n",
    "from generate_all_nuclear_masks import GenerateAllNuclearMasksJob\n",
    "from generate_all_distance_transforms import GenerateAllDistanceTransformsJob\n",
    "from generate_all_cropped_cell_images import GenerateAllCroppedCellImagesJob\n",
    "from generate_all_cell_result_lines import GenerateAllCellResultLinesJob\n",
    "from generate_cell_results_file import GenerateCellResultsFileJob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin interactive test analysis. Use the following four chunks to test the nuclear segmentation. If needed, change the diameter parameter to fine-tune the segmentation.\n",
    "\n",
    "#### Find all the fields in an experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define source folder\n",
    "source = source_path(IMAGE_LOCATION)\n",
    "\n",
    "#Find images within source folder by matching pattern\n",
    "all_images = source.rglob(str(ImageFilenameGlob(c=DAPI_CHANNEL, suffix=\"\", extension=\"tif\")))\n",
    "all_image_names = (ImageFilename.parse(str(image_file_path.relative_to(source))) for image_file_path in all_images)\n",
    "\n",
    "#Find positions\n",
    "def distinct_positions(image_names):\n",
    "    positions = set(ImageFilenameGlob.from_image_filename(image_filename, excluding_keys=[\"z\"]) for image_filename in image_names)\n",
    "    return positions\n",
    "\n",
    "positions = distinct_positions(all_image_names)\n",
    "positions_list = ([str(position) for position in positions])\n",
    "NUM_POSITIONS = len(positions_list)\n",
    "print(\"Found %i positions:\"%NUM_POSITIONS)\n",
    "print(*positions_list[:min(NUM_POSITIONS,10)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If more than nine images, take a random sample of the above table, load the images, and take a maximum projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_mp(pos):\n",
    "    stack = GenerateMaximumProjectionJob(source, pos, \"NULL\")\n",
    "    return stack.maximum_projection\n",
    "\n",
    "SAMPLE_SIZE = min(NUM_POSITIONS, 9)\n",
    "ROWS = (((SAMPLE_SIZE-1)//3) + 1)\n",
    "COLS = 3\n",
    "sample = random.sample(positions_list, SAMPLE_SIZE)\n",
    "imgs = [make_mp(position) for position in sample]\n",
    "\n",
    "fig, axs = pyplot.subplots(ROWS,COLS)\n",
    "\n",
    "for i in range(0,SAMPLE_SIZE):\n",
    "    ax = axs[i//3, i%3]\n",
    "    ax.imshow(imgs[i])\n",
    "for i in range(SAMPLE_SIZE,COLS*ROWS):\n",
    "    ax = axs[i//3, i%3]\n",
    "    ax.imshow(numpy.ones_like(imgs[SAMPLE_SIZE-1]))\n",
    "    \n",
    "fig.set_size_inches(COLS*5,ROWS*5)\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Cellpose(model_type='nuclei')\n",
    "\n",
    "masks, flows, styles, diams = model.eval([imgs[i] for i in range(0,SAMPLE_SIZE)], channels=[0,0], resample=True, do_3D=False, diameter=NUCLEAR_DIAMETER)\n",
    "\n",
    "print(numpy.shape(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Display the segmentation result and cell counts:\n",
    "def distinct_labels(label_matrix):\n",
    "  distinct_labels_set = set()\n",
    "  for labels_row in label_matrix:\n",
    "      for label in labels_row:\n",
    "          distinct_labels_set.add(label)\n",
    "  distinct_labels_set.remove(0)\n",
    "  return [label for label in distinct_labels_set]\n",
    "\n",
    "\n",
    "labels = [distinct_labels(masks[i]) for i in range(0,SAMPLE_SIZE)]\n",
    "\n",
    "fig, axs = pyplot.subplots(ROWS,COLS)\n",
    "\n",
    "for i in range(0,SAMPLE_SIZE):\n",
    "    ax = axs[i//3, i%3]\n",
    "    ax.imshow(imgs[i], cmap=\"Greys\")\n",
    "    if len(labels[i]) > 1:\n",
    "        ax.contourf(masks[i], levels=labels[i], alpha=0.2)\n",
    "        ax.text(0.0, 1.0, \"%i Cells\"%(max(labels[i])),\n",
    "            fontsize='medium', verticalalignment='top')\n",
    "    else:\n",
    "        ax.text(0.0, 1.0, \"No Cells\",\n",
    "            fontsize='medium', verticalalignment='top')\n",
    "for i in range(SAMPLE_SIZE,COLS*ROWS):\n",
    "    ax = axs[i//3, i%3]\n",
    "    ax.imshow(numpy.ones_like(imgs[SAMPLE_SIZE-1]))\n",
    "    \n",
    "fig.set_size_inches(COLS*5,ROWS*5)\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Like what you see? The chunks below will build a shell script to process your images with these parameters.\n",
    "\n",
    "##First: take the system variables that you set above and use them to generate directories for results folders. Worth checking that these are sensible to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SwarmJob.run_strategy = RunStrategy.SWARM\n",
    "\n",
    "scratch_directory = Path(\"/s/finn-lab/AG_0713\")\n",
    "results_directory = Path(\"/hpc-prj/finn/Results\")\n",
    "MIP_directory = scratch_directory / \"MIPs/\"\n",
    "nuclear_segmentations_directory = scratch_directory / \"segs/\" \n",
    "nuclear_masks_directory = scratch_directory / \"masks/\"\n",
    "distance_transforms_directory = scratch_directory / \"dts/\"\n",
    "cell_crops_directory = scratch_directory / \"crops/\"\n",
    "cell_result_lines_directory = scratch_directory / \"cell_results/\"\n",
    "\n",
    "log_files_directory = results_directory/ \"logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Finally: call scripts to find files, break them down into appropriate chunks for parallel processing, and write the command line calls into the shell script. \n",
    "\n",
    "Note that it's important to run each of these one-at-a-time, because the job submission system makes it seem like a job has completed before it really has. Run a chunk and wait to get an email that it's completed before moving on to the next one.\n",
    "\n",
    "Steps that this includes: \n",
    "1) Generate All Maximum Projections Job: Calculates maximum projections, weighted-average z positions, and vertically-integrated intensities\n",
    "2) Generate All Nuclear Segmentations Job: Uses CellPose to generate nuclear segmentations\n",
    "3) Generate All Nuclear Masks Job: Turns cellpose results into nuclear masks\n",
    "4) Generate All Distance Transforms Job: Uses nuclear masks to calculate normalized radial position for each pixel within the nucleus (0 = most central, 1 = most peripheral)\n",
    "5) Generate All Cropped Cell Images Job: crops images in all channels to get one cell and one channel per image\n",
    "6) Generate All Cell Result Lines Job: calculates integrated intensity in all channels, as well as cell size and shape parameters, for each cell\n",
    "7) Generate Cell Results File Job: concatenates cell result lines into a single tab separated file for downstream analysis\n",
    "\n",
    "### Each chunk will generate a shell script, run it, and email you approximately when it is completed. However, it is generally faster and more reliable to monitor the shell script using the \"squeue\" command on the command line. Do not run chunk two until the shell script in chunk one has finished running, since the files will not be all generated and will therefore get lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GenerateAllMaximumProjectionsJob(IMAGE_LOCATION, \n",
    "                                 MIP_directory, \n",
    "                                 log_files_directory).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GenerateAllNuclearSegmentationsJob(MIP_directory, \n",
    "                                   nuclear_segmentations_directory, \n",
    "                                   log_files_directory, \n",
    "                                   NUCLEAR_DIAMETER, DAPI_CHANNEL).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GenerateAllNuclearMasksJob(nuclear_segmentations_directory, \n",
    "                           nuclear_masks_directory, \n",
    "                           log_files_directory).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GenerateAllDistanceTransformsJob(nuclear_masks_directory, \n",
    "                                 distance_transforms_directory, \n",
    "                                 log_files_directory).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GenerateAllCroppedCellImagesJob(MIP_directory, \n",
    "                                nuclear_masks_directory, \n",
    "                                cell_crops_directory, \n",
    "                                log_files_directory, DAPI_CHANNEL).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GenerateAllCellResultLinesJob(MIP_directory, \n",
    "                                nuclear_masks_directory, \n",
    "                                cell_result_lines_directory, \n",
    "                                log_files_directory).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GenerateCellResultsFileJob(cell_result_lines_directory, results_directory, ANALYSIS_PREFIX).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
